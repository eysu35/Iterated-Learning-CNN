{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Load, partition, and resize CIFAR10 Data ##\n",
    "##############################################\n",
    "def loadData():\n",
    "    import pickle\n",
    "\n",
    "    # unpickle the binary files\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    labels = ['airplane',  # index 0\n",
    "          'automobile',  # index 1\n",
    "          'bird',  # index 2 \n",
    "          'cat',  # index 3 \n",
    "          'deer',  # index 4\n",
    "          'dog',  # index 5\n",
    "          'frog',  # index 6 \n",
    "          'horse',  # index 7 \n",
    "          'ship',  # index 8 \n",
    "          'truck']  # index 9\n",
    "    \n",
    "    # paths to each batch of data\n",
    "    batch1 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_5\")\n",
    "    meta = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/batches.meta\")\n",
    "    test = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/test_batch\")\n",
    "\n",
    "    # separate labels and image data from each batch\n",
    "    y_train1 = batch1[b'labels']\n",
    "    x_train1 = batch1[b'data']\n",
    "    y_train2 = batch2[b'labels']\n",
    "    x_train2 = batch2[b'data']\n",
    "    y_train3 = batch3[b'labels']\n",
    "    x_train3 = batch3[b'data']\n",
    "    y_train4 = batch4[b'labels']\n",
    "    x_train4 = batch4[b'data']\n",
    "    y_train5 = batch5[b'labels']\n",
    "    x_train5 = batch5[b'data']\n",
    "\n",
    "    # concatenate into big training and testing arrays\n",
    "    y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4, y_train5))\n",
    "    x_train = np.concatenate((x_train1, x_train2, x_train3, x_train4, x_train5), axis=0)\n",
    "    \n",
    "#     # shuffle the training data identically to before\n",
    "#     def shuffle_in_unison(x, y, permutation):\n",
    "#         assert x.shape[0] == y.shape[0]\n",
    "#         shuffled_x = np.empty(x.shape, dtype=x.dtype)\n",
    "#         shuffled_y = np.empty(y.shape, dtype=y.dtype)\n",
    "#         for old_index, new_index in enumerate(permutation):\n",
    "#             shuffled_x[new_index] = x[old_index]\n",
    "#             shuffled_y[new_index] = y[old_index]\n",
    "\n",
    "#         return shuffled_x, shuffled_y\n",
    "\n",
    "#     permutation = np.loadtxt('/scratch/gpfs/eysu/src_data/cifar-10-batches-py/permutation.csv', delimiter=',').astype(np.int64)\n",
    "\n",
    "#     x_train, y_train = shuffle_in_unison(x_train, y_train, permutation)\n",
    "\n",
    "    y_test = test[b'labels']\n",
    "    x_test = test[b'data']\n",
    "    \n",
    "    # Further break training data into train / validation sets \n",
    "    # put 5000 into validation set and keep remaining 45,000 for train\n",
    "    (x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "    (y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "    # reshape data to match dimensions of cifar10.load_data\n",
    "    x_train = x_train.reshape(45000, 3, 32, 32)\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train /= 255\n",
    "\n",
    "    # y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "\n",
    "    x_valid = x_valid.reshape(5000, 3, 32, 32)\n",
    "    x_valid = x_valid.transpose(0, 2, 3, 1)\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_valid /= 255\n",
    "\n",
    "    x_test = x_test.reshape(10000, 3, 32, 32)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_valid = np.array(y_valid)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, labels\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665db25",
   "metadata": {},
   "source": [
    "# Analysis 1: Divisions of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffde980",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Examine the divisions in classes across iterations ##\n",
    "########################################################\n",
    "# load the hard labels sampled after every iteration for every image\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "\n",
    "# store all divisions of classes in array\n",
    "# dimensions are iters x classes\n",
    "divisions = np.zeros((all_labels.shape[1], 10))\n",
    "\n",
    "for i in range(all_labels.shape[1]):\n",
    "    _, counts = np.unique(all_labels[:, i], return_counts=True)\n",
    "    divisions[i] = counts\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for j in range(10):\n",
    "    x = np.arange(all_labels.shape[1])\n",
    "    plt.plot(x, divisions[:, j], label = \"Class: \" + labels[j])\n",
    "    \n",
    "plt.title(\"Divisions of Classes over 1000 Iterations on Untrained Model\")\n",
    "plt.ylim([0, 12000])\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d783706",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Examine the divisions in classes across iterations ##\n",
    "########################################################\n",
    "from scipy.stats import entropy\n",
    "# load the hard labels sampled after every iteration for every image\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_CIFAR_1000/labels.npy\")\n",
    "\n",
    "# store all divisions of classes in array\n",
    "# dimensions are iters x classes\n",
    "divisions = np.zeros((all_labels.shape[1], 10))\n",
    "\n",
    "for i in range(all_labels.shape[1]):\n",
    "    _, counts = np.unique(all_labels[:, i], return_counts=True)\n",
    "    divisions[i] = counts\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for j in range(10):\n",
    "    x = np.arange(all_labels.shape[1])\n",
    "    plt.plot(x, divisions[:, j], label = \"Class: \" + labels[j])\n",
    "    \n",
    "    ent = entropy(divisions[:, j])\n",
    "    print(ent)\n",
    "    \n",
    "plt.title(\"Divisions of Classes over 1000 Iterations on Pretrained Model\")\n",
    "plt.ylim([0, 12000])\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca34293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf02d72",
   "metadata": {},
   "source": [
    "# Analysis 2: Examine images of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377adc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Look at 10 random images labeled as each class at each 200 iteration mark ##\n",
    "###############################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "#     pdf = PdfPages('/home/eysu/Sampling/Outputs/Untrained_Class_' + str(CLASS) + '.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "   \n",
    "        # print 10 random images from the correctly labeled subset\n",
    "        rand_idx = np.random.randint(0, high=class_labels.shape[1], size=10)\n",
    "    \n",
    "        for j in rand_idx:\n",
    "            fig = plt.figure()\n",
    "            plt.imshow(class_imgs[j])\n",
    "            plt.title(\"Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "            plt.show()\n",
    "            \n",
    "#             pdf.savefig(fig, bbox_inches = 'tight')\n",
    "#     pdf.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Look at 10 random images labeled as each class at each 200 iteration mark ##\n",
    "###############################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/Pretrained_Class_' + str(CLASS) + '.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "   \n",
    "        # print 10 random images from the correctly labeled subset\n",
    "        rand_idx = np.random.randint(0, high=class_labels.shape[1], size=10)\n",
    "    \n",
    "        for j in rand_idx:\n",
    "            fig = plt.figure()\n",
    "            plt.imshow(class_imgs[j])\n",
    "            plt.title(\"Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "            plt.show()\n",
    "            \n",
    "            pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3795408",
   "metadata": {},
   "source": [
    "# Analysis 3: Mean Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c447c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "# w, h = 32, 32\n",
    "# x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/CIFAR_Untrained_Class_' + str(CLASS) + '_mean_img.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(mean_img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(\"Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "        plt.show()\n",
    "        \n",
    "        pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "### SAME THING JUST PLOT ALL TOGETHER ##### \n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "# w, h = 28, 28\n",
    "# x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/CIFAR_Untrained_Class_mean_imgs.pdf')\n",
    "fig, axes = plt.subplots(6, 10, figsize=(15, 8))\n",
    "\n",
    "plt.setp(axes, xticks=[], xticklabels=[],\n",
    "        yticks=[])\n",
    "plt.suptitle(\"Average Images of Each Class Label by Iteration for Untrained Model\")\n",
    "for CLASS in range(10):\n",
    "    for i, iter in enumerate([0, 200, 400, 600, 800, 1000]):\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        \n",
    "        axes[i, CLASS].imshow(mean_img)\n",
    "        if i == 0:\n",
    "            axes[i, CLASS].set_title(labels[CLASS])\n",
    "            \n",
    "        if CLASS == 0:\n",
    "            axes[i, CLASS].set_ylabel(\"Iter \" + str(iter))\n",
    "\n",
    "plt.show()\n",
    "        \n",
    "pdf.savefig(fig, bbox_inches = 'tight')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also show mean image of all data\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/mean_img_all_data.pdf')\n",
    "\n",
    "\n",
    "mean_total = np.array(np.mean(x_train, axis=0))\n",
    "fig = plt.imshow(mean_total)\n",
    "plt.title(\"Dataset average\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "pdf.savefig(fig, bboc_inches = 'tight')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "# w, h = 28, 28\n",
    "# x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_CIFAR_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/CIFAR_Pretrained_Class_' + str(CLASS) + '_mean_img.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(mean_img)\n",
    "        plt.title(\"Mean Image of Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "        plt.show()\n",
    "        \n",
    "        pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "### SAME THING JUST PLOT ALL TOGETHER ##### \n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "# w, h = 28, 28\n",
    "# x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_CIFAR_1000/labels.npy\")\n",
    "pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/CIFAR_Pretrained_Class_mean_imgs.pdf')\n",
    "fig, axes = plt.subplots(6, 10, figsize=(15, 8))\n",
    "\n",
    "plt.setp(axes, xticks=[], xticklabels=[],\n",
    "        yticks=[])\n",
    "plt.suptitle(\"Average Images of Each Class Label by Iteration for Pretrained Model\")\n",
    "for CLASS in range(10):\n",
    "    for i, iter in enumerate([0, 200, 400, 600, 800, 1000]):\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        \n",
    "        axes[i, CLASS].imshow(mean_img)\n",
    "        if i == 0:\n",
    "            axes[i, CLASS].set_title(labels[CLASS])\n",
    "            \n",
    "        if CLASS == 0:\n",
    "            axes[i, CLASS].set_ylabel(\"Iter \" + str(iter))\n",
    "\n",
    "plt.show()\n",
    "        \n",
    "pdf.savefig(fig, bbox_inches = 'tight')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1681a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b59393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39a26d69",
   "metadata": {},
   "source": [
    "# Analysis 4: Cluster Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b536f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "## Find the similarity of each iter labels to original seed labels ##\n",
    "#####################################################################\n",
    "# aka how many images are correctly labeled\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "\n",
    "true_labels = all_labels[:, 0]\n",
    "\n",
    "x = np.arange(all_labels.shape[1])\n",
    "all_sims = np.zeros((11, all_labels.shape[1]))\n",
    "for iter in range(all_labels.shape[1]):\n",
    "    iter_labels = all_labels[:, iter]\n",
    "    avg_sim = adjusted_rand_score(true_labels, iter_labels)\n",
    "    all_sims[10, iter] = avg_sim\n",
    "    \n",
    "    # also find each class's similarity score\n",
    "    for CLASS in range(10):\n",
    "        true_class_labels = true_labels == CLASS\n",
    "        pred_class_labels = iter_labels == CLASS\n",
    "        \n",
    "        # calculate similarity score\n",
    "        class_sim = adjusted_rand_score(true_class_labels, pred_class_labels)\n",
    "        all_sims[CLASS, iter] = class_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "for i in range(11):\n",
    "    if i == 10:\n",
    "        plt.plot(x, all_sims[i, :], label=\"Average Similarity\", linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(x, all_sims[i, :], label=labels[i], linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Similarity Between Predicted and True Labels (Untrained Model)\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758919c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "## Find the similarity of each iter labels to original seed labels ##\n",
    "#####################################################################\n",
    "# aka how many images are correctly labeled\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_CIFAR_1000/labels.npy\")\n",
    "\n",
    "true_labels = all_labels[:, 0]\n",
    "\n",
    "x = np.arange(all_labels.shape[1])\n",
    "all_sims = np.zeros((11, all_labels.shape[1]))\n",
    "for iter in range(all_labels.shape[1]):\n",
    "    iter_labels = all_labels[:, iter]\n",
    "    avg_sim = adjusted_rand_score(true_labels, iter_labels)\n",
    "    all_sims[10, iter] = avg_sim\n",
    "    \n",
    "    # also find each class's similarity score\n",
    "    for CLASS in range(10):\n",
    "        true_class_labels = true_labels == CLASS\n",
    "        pred_class_labels = iter_labels == CLASS\n",
    "        \n",
    "        # calculate similarity score\n",
    "        class_sim = adjusted_rand_score(true_class_labels, pred_class_labels)\n",
    "        all_sims[CLASS, iter] = class_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7189328",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "for i in range(11):\n",
    "    if i == 10:\n",
    "        plt.plot(x, all_sims[i, :], label=\"Average Similarity\", linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(x, all_sims[i, :], label=labels[i], linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Similarity Between Predicted and True Labels (Pretrained Model)\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d0b850",
   "metadata": {},
   "source": [
    "# Analysis 5: Label Changing Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "\n",
    "rand_idx = np.random.randint(0, all_labels.shape[0])\n",
    "\n",
    "# save the true class to include it in title\n",
    "true_cl = all_labels[rand_idx, 0]\n",
    "x = np.arange(all_labels.shape[1])\n",
    "\n",
    "plt.scatter(x, all_labels[rand_idx, :], marker = 'o', s = 2, c = '#2ca02c')\n",
    "\n",
    "\n",
    "plt.title(\"Label Changes for a Class \" + labels[int(true_cl)] + \" Image\")\n",
    "plt.ylabel(\"Sampled Label Class\")\n",
    "plt.yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], labels=labels)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7547555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7788f68",
   "metadata": {},
   "source": [
    "# Analysis 6: CIFAR10H Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## Compare the fractions of label classes with the CIFAR10H dataset ##\n",
    "######################################################################\n",
    "\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR2_1000/test_labels.npy\")\n",
    "soft = np.load('/scratch/gpfs/eysu/src_data/cifar-10h/data/cifar10h-probs.npy')\n",
    "\n",
    "cos_sims = np.zeros(soft.shape[0])\n",
    "\n",
    "\n",
    "# find the fractional divisions of labels over some slice of labels\n",
    "for i in range(all_labels.shape[0]):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # find fraction of each class label \n",
    "    vals, num_labels = np.unique(all_labels[i][:900], return_counts=True)\n",
    "    if len(vals) == 10:\n",
    "        frac_labels = num_labels / all_labels.shape[1]\n",
    "    \n",
    "    else:\n",
    "        frac_labels = np.zeros((10,))\n",
    "        for i, num in enumerate(vals):\n",
    "            frac_labels[int(num)] = num_labels[i]\n",
    "        frac_labels = frac_labels / all_labels.shape[1]\n",
    "    \n",
    "    cos_sim = np.dot(soft[i], frac_labels) / (np.linalg.norm(soft[i])* np.linalg.norm(frac_labels))\n",
    "\n",
    "    cos_sims[i] = cos_sim\n",
    "\n",
    "x = np.arange(all_labels.shape[0])\n",
    "plt.scatter(x, cos_sims, marker='.', linewidths=0.05)\n",
    "plt.title(\"Similarity Between Fractions of Sampled Labels to \\nHuman Soft Similarity Lables (Iteration 900)\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.xlabel(\"Test Image Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033b1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06de282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Find the entropy of class distributions ##\n",
    "#############################################\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# load the hard labels sampled after every iteration for every image\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/CIFAR_1000/labels.npy\")\n",
    "\n",
    "# store all divisions of classes in array\n",
    "# dimensions are iters x classes\n",
    "divisions = np.zeros((all_labels.shape[0], 10))\n",
    "\n",
    "for i in range(all_labels.shape[0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    vals, counts = np.unique(all_labels[i], return_counts=True)\n",
    "    counts = counts / all_labels.shape[1]\n",
    "    if len(vals) ==10:\n",
    "        divisions[i] = counts \n",
    "        \n",
    "    else:\n",
    "        for j, val in enumerate(vals):\n",
    "            divisions[i, int(val)] = counts[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(entropy(divisions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f816a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
