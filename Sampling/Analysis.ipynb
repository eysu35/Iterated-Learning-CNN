{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Load, partition, and resize MNIST Digits ##\n",
    "##############################################\n",
    "\n",
    "def loadData():\n",
    "    all_data = np.load(\"/scratch/gpfs/eysu/src_data/mnist.npz\")\n",
    "\n",
    "    x_test = all_data['x_test']\n",
    "    x_train = all_data['x_train']\n",
    "    y_train = all_data['y_train']\n",
    "    y_test = all_data['y_test']\n",
    "\n",
    "    labels = [\"0\",  # index 0\n",
    "              \"1\",  # index 1\n",
    "              \"2\",  # index 2 \n",
    "              \"3\",  # index 3 \n",
    "              \"4\",  # index 4\n",
    "              \"5\",  # index 5\n",
    "              \"6\",  # index 6 \n",
    "              \"7\",  # index 7 \n",
    "              \"8\",  # index 8 \n",
    "              \"9\"]  # index 9\n",
    "\n",
    "    # save train labels\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "\n",
    "    # y_train_labels = y_train\n",
    "    # y_test_labels = y_test\n",
    "\n",
    "    # Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "    (x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "    (y_train, y_valid) = y_train[5000:], np.array(y_train[:5000]).squeeze()\n",
    "\n",
    "    # Reshape input data from (28, 28) to (28, 28, 1)\n",
    "    w, h = 28, 28\n",
    "    x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665db25",
   "metadata": {},
   "source": [
    "# Analysis 1: Divisions of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffde980",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Examine the divisions in classes across iterations ##\n",
    "########################################################\n",
    "# load the hard labels sampled after every iteration for every image\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "\n",
    "# store all divisions of classes in array\n",
    "# dimensions are iters x classes\n",
    "divisions = np.zeros((all_labels.shape[1], 10))\n",
    "\n",
    "for i in range(all_labels.shape[1]):\n",
    "    _, counts = np.unique(all_labels[:, i], return_counts=True)\n",
    "    divisions[i] = counts\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for j in range(10):\n",
    "    x = np.arange(all_labels.shape[1])\n",
    "    plt.plot(x, divisions[:, j], label = \"Class: \" + str(j))\n",
    "    \n",
    "plt.title(\"Divisions of Classes over 1000 Iterations on Untrained Model\")\n",
    "plt.ylim([0, 12000])\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d783706",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Examine the divisions in classes across iterations ##\n",
    "########################################################\n",
    "# load the hard labels sampled after every iteration for every image\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "\n",
    "# store all divisions of classes in array\n",
    "# dimensions are iters x classes\n",
    "divisions = np.zeros((all_labels.shape[1], 10))\n",
    "\n",
    "for i in range(all_labels.shape[1]):\n",
    "    _, counts = np.unique(all_labels[:, i], return_counts=True)\n",
    "    divisions[i] = counts\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for j in range(10):\n",
    "    x = np.arange(all_labels.shape[1])\n",
    "    plt.plot(x, divisions[:, j], label = \"Class: \" + str(j))\n",
    "\n",
    "    \n",
    "plt.title(\"Divisions of Classes over 1000 Iterations on Pretrained Model\")\n",
    "plt.ylim([0, 12000])\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca34293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf02d72",
   "metadata": {},
   "source": [
    "# Analysis 2: Examine images of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377adc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Look at 10 random images labeled as each class at each 200 iteration mark ##\n",
    "###############################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/Untrained_Class_' + str(CLASS) + '.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "   \n",
    "        # print 10 random images from the correctly labeled subset\n",
    "        rand_idx = np.random.randint(0, high=class_labels.shape[1], size=10)\n",
    "    \n",
    "        for j in rand_idx:\n",
    "            fig = plt.figure()\n",
    "            plt.imshow(class_imgs[j])\n",
    "            plt.title(\"Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "            plt.show()\n",
    "            \n",
    "            pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Look at 10 random images labeled as each class at each 200 iteration mark ##\n",
    "###############################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/Pretrained_Class_' + str(CLASS) + '.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "   \n",
    "        # print 10 random images from the correctly labeled subset\n",
    "        rand_idx = np.random.randint(0, high=class_labels.shape[1], size=10)\n",
    "    \n",
    "        for j in rand_idx:\n",
    "            fig = plt.figure()\n",
    "            plt.imshow(class_imgs[j])\n",
    "            plt.title(\"Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "            plt.show()\n",
    "            \n",
    "            pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea6f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3795408",
   "metadata": {},
   "source": [
    "# Analysis 3: Mean Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c447c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/Untrained_Class_' + str(CLASS) + '_mean_img.pdf')\n",
    "    for iter in [1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(mean_img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(\"Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "        plt.show()\n",
    "        \n",
    "        pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "### SAME THING JUST PLOT ALL TOGETHER ##### \n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/Untrained_Class_mean_imgs.pdf')\n",
    "fig, axes = plt.subplots(6, 10, figsize=(15, 8))\n",
    "\n",
    "plt.setp(axes, xticks=[], xticklabels=[],\n",
    "        yticks=[])\n",
    "plt.suptitle(\"Difference Between Average Images of Each Class and Dataset Average for Untrained Model\")\n",
    "for CLASS in range(10):\n",
    "    for i, iter in enumerate([0, 200, 400, 600, 800, 1000]):\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        # uncomment the below line to show the difference between the class means and the total mean\n",
    "        mean_img = mean_total - mean_img\n",
    "        \n",
    "        axes[i, CLASS].imshow(mean_img)\n",
    "        if i == 0:\n",
    "            axes[i, CLASS].set_title(\"Class \" + str(CLASS))\n",
    "            \n",
    "        if CLASS == 0:\n",
    "            axes[i, CLASS].set_ylabel(\"Iter \" + str(iter))\n",
    "\n",
    "plt.show()\n",
    "        \n",
    "pdf.savefig(fig, bbox_inches = 'tight')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also show mean image of all data\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/mean_img_all_data.pdf')\n",
    "\n",
    "\n",
    "mean_total = np.array(np.mean(x_train, axis=0))\n",
    "fig = plt.imshow(mean_total)\n",
    "plt.title(\"Dataset average\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "# pdf.savefig(fig)\n",
    "# pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "\n",
    "for CLASS in range(10):\n",
    "    pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/Pretrained_Class_' + str(CLASS) + '_mean_img.pdf')\n",
    "    for iter in [0, 200, 400, 600, 800, 1000]:\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(mean_img)\n",
    "        plt.title(\"Mean Image of Class \" + str(CLASS) + \", iteration \" + str(iter))\n",
    "        plt.show()\n",
    "        \n",
    "        pdf.savefig(fig, bbox_inches = 'tight')\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc9865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## Find the average image for each class and iteration interval ##\n",
    "##################################################################\n",
    "### SAME THING JUST PLOT ALL TOGETHER ##### \n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n",
    "\n",
    "#reshape images back to 28x28\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h)\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "pdf = PdfPages('/home/eysu/Sampling/Outputs/mean_imgs/Pretrained_Class_mean_imgs.pdf')\n",
    "fig, axes = plt.subplots(6, 10, figsize=(15, 8))\n",
    "\n",
    "plt.setp(axes, xticks=[], xticklabels=[],\n",
    "        yticks=[])\n",
    "plt.suptitle(\"Difference Between Average Images of Each Class and Dataset Average for Pretrained Model\")\n",
    "for CLASS in range(10):\n",
    "    for i, iter in enumerate([0, 200, 400, 600, 800, 1000]):\n",
    "        # isolate the labels and images that are labeled as CLASS\n",
    "        class_idxs = np.where(all_labels[:, iter] == CLASS)\n",
    "        class_labels = all_labels[class_idxs, iter]\n",
    "        # double check that only the images labeled with CLASS at that iter have been selected\n",
    "        assert np.unique(class_labels[:, iter])[0] == CLASS\n",
    "        class_imgs = x_train[class_idxs]\n",
    "        \n",
    "        # find the mean image for each class at each iteration\n",
    "        mean_img = np.array(np.mean(class_imgs, axis=0))\n",
    "\n",
    "        # uncomment the below line to show the difference between the class means and the total mean\n",
    "        mean_img = mean_total - mean_img\n",
    "        \n",
    "        axes[i, CLASS].imshow(mean_img)\n",
    "        if i == 0:\n",
    "            axes[i, CLASS].set_title(\"Class \" + str(CLASS))\n",
    "            \n",
    "        if CLASS == 0:\n",
    "            axes[i, CLASS].set_ylabel(\"Iter \" + str(iter))\n",
    "\n",
    "plt.show()\n",
    "        \n",
    "pdf.savefig(fig, bbox_inches = 'tight')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1681a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b59393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "a = [True]\n",
    "b = [False]\n",
    "print(adjusted_rand_score(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a26d69",
   "metadata": {},
   "source": [
    "# Analysis 4: Cluster Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b536f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "## Find the similarity of each iter labels to original seed labels ##\n",
    "#####################################################################\n",
    "# aka how many images are correctly labeled\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "\n",
    "true_labels = all_labels[:, 0]\n",
    "\n",
    "x = np.arange(all_labels.shape[1])\n",
    "all_sims = np.zeros((11, all_labels.shape[1]))\n",
    "for iter in range(all_labels.shape[1]):\n",
    "    iter_labels = all_labels[:, iter]\n",
    "    avg_sim = adjusted_rand_score(true_labels, iter_labels)\n",
    "    all_sims[10, iter] = avg_sim\n",
    "    \n",
    "    # also find each class's similarity score\n",
    "    for CLASS in range(10):\n",
    "        true_class_labels = true_labels == CLASS\n",
    "        pred_class_labels = iter_labels == CLASS\n",
    "        \n",
    "        # calculate similarity score\n",
    "        class_sim = adjusted_rand_score(true_class_labels, pred_class_labels)\n",
    "        all_sims[CLASS, iter] = class_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "for i in range(11):\n",
    "    if i == 10:\n",
    "        plt.plot(x, all_sims[i, :], label=\"Average Similarity\", linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(x, all_sims[i, :], label=\"Class: \" + str(i), linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Similarity Between Predicted and True Labels (Untrained Model)\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758919c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "## Find the similarity of each iter labels to original seed labels ##\n",
    "#####################################################################\n",
    "# aka how many images are correctly labeled\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "\n",
    "true_labels = all_labels[:, 0]\n",
    "\n",
    "x = np.arange(all_labels.shape[1])\n",
    "all_sims = np.zeros((11, all_labels.shape[1]))\n",
    "for iter in range(all_labels.shape[1]):\n",
    "    iter_labels = all_labels[:, iter]\n",
    "    avg_sim = adjusted_rand_score(true_labels, iter_labels)\n",
    "    all_sims[10, iter] = avg_sim\n",
    "    \n",
    "    # also find each class's similarity score\n",
    "    for CLASS in range(10):\n",
    "        true_class_labels = true_labels == CLASS\n",
    "        pred_class_labels = iter_labels == CLASS\n",
    "        \n",
    "        # calculate similarity score\n",
    "        class_sim = adjusted_rand_score(true_class_labels, pred_class_labels)\n",
    "        all_sims[CLASS, iter] = class_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i in range(11):\n",
    "    if i == 10:\n",
    "        plt.plot(x, all_sims[i, :], label=\"Average Similarity\", linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(x, all_sims[i, :], label=\"Class: \" + str(i), linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Similarity Between Predicted and True Labels (Pretrained Model)\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d0b850",
   "metadata": {},
   "source": [
    "# Analysis 5: Label Changing Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels from training\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/MNIST_1000/labels.npy\")\n",
    "\n",
    "rand_idx = np.random.randint(0, all_labels.shape[0])\n",
    "\n",
    "# save the true class to include it in title\n",
    "true_cl = all_labels[rand_idx, 0]\n",
    "x = np.arange(all_labels.shape[1])\n",
    "\n",
    "plt.scatter(x, all_labels[rand_idx, :], marker = 'o', s = 2, c = '#2ca02c')\n",
    "\n",
    "\n",
    "plt.title(\"Label Changes for a Class \" + str(int(true_cl)) + \" Image\")\n",
    "plt.ylabel(\"Sampled Label Class\")\n",
    "plt.yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7547555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7788f68",
   "metadata": {},
   "source": [
    "# Analysis 6: Entropy of Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Find the entropy of class distributions ##\n",
    "#############################################\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# load the hard labels sampled after every iteration for every image\n",
    "all_labels = np.load(\"/scratch/gpfs/eysu/Sampling/pretrained_1000/labels.npy\")\n",
    "\n",
    "# store all divisions of classes in array\n",
    "# dimensions are iters x classes\n",
    "divisions = np.zeros((all_labels.shape[0], 10))\n",
    "\n",
    "for i in range(all_labels.shape[0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    vals, counts = np.unique(all_labels[i], return_counts=True)\n",
    "    counts = counts / all_labels.shape[1]\n",
    "    if len(vals) ==10:\n",
    "        divisions[i] = counts \n",
    "        \n",
    "    else:\n",
    "        for j, val in enumerate(vals):\n",
    "            divisions[i, int(val)] = counts[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(entropy(divisions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc40db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
