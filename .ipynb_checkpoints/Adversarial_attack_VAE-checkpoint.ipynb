{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0da6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf; tf.compat.v1.disable_eager_execution()\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Flatten, Lambda, Reshape\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.datasets import mnist\n",
    "# np.random.seed(25)\n",
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 55000 x 25 matrices if 25 nearest in class neighbors and their norms\n",
    "nearest_neighbors_in_class = pd.read_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_in_class.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_in_class_norms = pd.read_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_norms.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class = pd.read_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_other_class.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class_norms = pd.read_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_norms.csv\", sep = ',', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nearest_neighbors_other_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "## This cell is for selecting the dataset --- Digits or Fashion (MNIST toy world) ##\n",
    "####################################################################################\n",
    "\n",
    "DATASET = '_DigitMNIST' \n",
    "# DATASET = '_FashionMNIST'\n",
    "REGIME = '_TRAINED_' # '_RANDOM_'\n",
    "\n",
    "if DATASET == '_DigitMNIST':\n",
    "    # Load the digit-mnist pre-shuffled train data and test data\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() #digit_mnist\n",
    "    print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "    # Define the text labels\n",
    "    labels = [\"0\",  # index 0\n",
    "                            \"1\",  # index 1\n",
    "                            \"2\",  # index 2 \n",
    "                            \"3\",  # index 3 \n",
    "                            \"4\",  # index 4\n",
    "                            \"5\",  # index 5\n",
    "                            \"6\",  # index 6 \n",
    "                            \"7\",  # index 7 \n",
    "                            \"8\",  # index 8 \n",
    "                            \"9\"]  # index 9\n",
    "\n",
    "else:\n",
    "    # Load the fashion-mnist pre-shuffled train data and test data\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() #fashion_mnist\n",
    "    print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "    # Define the text labels\n",
    "    labels = [\"T-shirt\",  # index 0\n",
    "                            \"Trouser\",      # index 1\n",
    "                            \"Pullover\",     # index 2 \n",
    "                            \"Dress\",        # index 3 \n",
    "                            \"Coat\",         # index 4\n",
    "                            \"Sandal\",       # index 5\n",
    "                            \"Shirt\",        # index 6 \n",
    "                            \"Sneaker\",      # index 7 \n",
    "                            \"Bag\",          # index 8 \n",
    "                            \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# save train labels\n",
    "y_train_labels = y_train\n",
    "y_test_labels = y_test\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# Validation set\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 0\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from (no_of_data, 28, 28) to (no_of_data, 28, 28, 1)\n",
    "X_train_new = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "X_test_new = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0329ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Standard boilerplate ##########################################\n",
    "# citation: https://becominghuman.ai/using-variational-autoencoder-vae-to-generate-new-images-14328877e88d\n",
    "#############################################################################################################\n",
    "\n",
    "img_height   = X_train_new.shape[1]    # 28\n",
    "img_width    = X_train_new.shape[2]    # 28\n",
    "num_channels = X_train_new.shape[3]    # 1\n",
    "input_shape =  (img_height, img_width, num_channels)   # (28,28,1)\n",
    "latent_dim = 6    # Dimension of the latent space\n",
    "\n",
    "# Encoder\n",
    "encoder_input = Input(shape=input_shape)\n",
    "encoder_conv = Conv2D(filters=8, kernel_size=3, strides=2, \n",
    "                padding='same', activation='relu')(encoder_input)\n",
    "encoder_conv = Conv2D(filters=16, kernel_size=3, strides=2, \n",
    "                padding='same', activation='relu')(encoder_input)\n",
    "encoder = Flatten()(encoder_conv)\n",
    "\n",
    "mu = Dense(latent_dim)(encoder)\n",
    "sigma = Dense(latent_dim)(encoder)\n",
    "\n",
    "def compute_latent(x):\n",
    "    mu, sigma = x\n",
    "    batch = K.shape(mu)[0]\n",
    "    dim = K.int_shape(mu)[1]\n",
    "    eps = K.random_normal(shape=(batch,dim))\n",
    "    return mu + K.exp(sigma/2)*eps\n",
    "\n",
    "latent_space = Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])\n",
    "conv_shape = K.int_shape(encoder_conv)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "decoder = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)\n",
    "decoder = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(decoder)\n",
    "decoder_conv = Conv2DTranspose(filters=16, kernel_size=3, strides=2, \n",
    "                           padding='same', activation='relu')(decoder)\n",
    "decoder_conv = Conv2DTranspose(filters=8, kernel_size=3, strides=2, \n",
    "                           padding='same', activation='relu')(decoder)\n",
    "decoder_conv =  Conv2DTranspose(filters=num_channels, kernel_size=3, \n",
    "                          padding='same', activation='sigmoid')(decoder_conv)\n",
    "\n",
    "# Connect encoder and decoder\n",
    "encoder = Model(encoder_input, latent_space)\n",
    "decoder = Model(decoder_input, decoder_conv)\n",
    "\n",
    "# VAE\n",
    "vae = Model(encoder_input, decoder(encoder(encoder_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_reconstruction_loss(true, pred):\n",
    "    # Reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * img_width * img_height\n",
    "    # KL divergence loss\n",
    "    kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    # Total loss = 50% rec + 50% KL divergence loss\n",
    "    return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "vae.compile(optimizer='adam', loss=kl_reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2add878",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae.fit(x=X_train_new, y=X_train_new, epochs=20, batch_size=32, validation_data=(X_test_new,X_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db761cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "##### ###################for generating morphs between vectors in the latent space ######################\n",
    "#########################################################################################################\n",
    "\n",
    "#==> generalize this for arbitrary dimensionality of z space\n",
    "#==> add titles, and path vectors through the space\n",
    "#==> Don't use linspace!!!!\n",
    "\n",
    "def display_image_sequence(s1,s2,s3,s4,s5,s6,e1,e2,e3,e4,e5,e6,no_of_imgs,s_im,e_im):\n",
    "    d1 = np.linspace(s1,e1,no_of_imgs)\n",
    "    d2 = np.linspace(s2,e2,no_of_imgs)\n",
    "    d3 = np.linspace(s3,e3,no_of_imgs)    \n",
    "    d4 = np.linspace(s4,e4,no_of_imgs)\n",
    "    d5 = np.linspace(s5,e5,no_of_imgs)\n",
    "    d6 = np.linspace(s6,e6,no_of_imgs)\n",
    "    \n",
    "    d1 = d1[:, np.newaxis]\n",
    "    d2 = d2[:, np.newaxis]\n",
    "    d3 = d3[:, np.newaxis]\n",
    "    d4 = d4[:, np.newaxis]    \n",
    "    d5 = d5[:, np.newaxis]\n",
    "    d6 = d6[:, np.newaxis]\n",
    "    \n",
    "    new_points = np.hstack((d1,d2,d3,d4,d5,d6))\n",
    "    new_images = decoder.predict(new_points)\n",
    "    new_images = new_images.reshape(new_images.shape[0], new_images.shape[1], new_images.shape[2])\n",
    "    \n",
    "    # Display some images\n",
    "    fig, axes = plt.subplots(ncols=no_of_imgs+2, sharex=False,\n",
    "                             sharey=True, figsize=(20, 7))\n",
    "    counter = 1\n",
    "    axes[0].imshow(s_im, cmap='gray')\n",
    "    for i in range(0,no_of_imgs):        \n",
    "        axes[counter].imshow(new_images[i], cmap='gray')\n",
    "        axes[counter].get_xaxis().set_visible(False)\n",
    "        axes[counter].get_yaxis().set_visible(False)\n",
    "        counter += 1\n",
    "    axes[counter].imshow(e_im, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1241331",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLASS = 2\n",
    "rank = pd.read_csv(\"Outputs/Seed_diff_ranks/ranked_\" + str(labels[CLASS]) + \"s.csv\", sep=',', header=None).to_numpy().squeeze()\n",
    "print(rank.shape)\n",
    "    \n",
    "# get index of least confusing 0, take the first entry of the 0 rankings\n",
    "image_idx = rank[5000]\n",
    "NN_other_class = nearest_neighbors_other_class[image_idx, 0]\n",
    "NN_other_class_norm = nearest_neighbors_other_class_norms[image_idx, 0]\n",
    "orig = X_train_new[image_idx,:,:,:]\n",
    "\n",
    "plt.imshow(orig, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_train_new[NN_other_class,:,:,:], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Original images ordered by rank (smaller indices are more confusable)\n",
    "origs = encoder.predict(X_train_new[rank,:,:,:])\n",
    "# nearest neighbor examples, also ordered by rank. Take first nearest neighbor\n",
    "knns_out = encoder.predict(X_train_new[nearest_neighbors_other_class[rank, 0],:,:,:])\n",
    "\n",
    "# frames\n",
    "fn = 20\n",
    "# Generate some morphs \n",
    "for rnk in range(5000,len(rank)):\n",
    "    image_idx = rank[rnk]\n",
    "    NN_other_class = nearest_neighbors_other_class[image_idx, 0]\n",
    "    NN_other_class_norm = nearest_neighbors_other_class_norms[image_idx, 0]\n",
    "    # original image, and nearest neighbor (out of class)\n",
    "    orig_im = X_train_new[image_idx,:,:,:]\n",
    "    knn_im = X_train_new[NN_other_class,:,:,:]\n",
    "    # generate morph (linear interpolation) in latent space, and synthesize images\n",
    "    display_image_sequence(origs[rnk][0],origs[rnk][1],origs[rnk][2],origs[rnk][3],origs[rnk][4],origs[rnk][5],\n",
    "                                 knns_out[rnk][0],knns_out[rnk][1],knns_out[rnk][2],knns_out[rnk][3],knns_out[rnk][4],knns_out[rnk][5],\n",
    "                                 fn,orig_im,knn_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f9060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 [anaconda/2019.3]",
   "language": "python",
   "name": "sys_python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
