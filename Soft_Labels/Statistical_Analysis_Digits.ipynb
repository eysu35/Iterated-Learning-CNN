{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc8b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Libraries ##\n",
    "###############\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdb697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Load, partition, and resize MNIST Digits ##\n",
    "##############################################\n",
    "def loadData():\n",
    "    all_data = np.load(\"/scratch/gpfs/eysu/src_data/mnist.npz\")\n",
    "\n",
    "    x_test = all_data['x_test']\n",
    "    x_train = all_data['x_train']\n",
    "    y_train = all_data['y_train']\n",
    "    y_test = all_data['y_test']\n",
    "\n",
    "    labels = [\"0\",  # index 0\n",
    "              \"1\",  # index 1\n",
    "              \"2\",  # index 2 \n",
    "              \"3\",  # index 3 \n",
    "              \"4\",  # index 4\n",
    "              \"5\",  # index 5\n",
    "              \"6\",  # index 6 \n",
    "              \"7\",  # index 7 \n",
    "              \"8\",  # index 8 \n",
    "              \"9\"]  # index 9\n",
    "\n",
    "    # save train labels\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "\n",
    "    # y_train_labels = y_train\n",
    "    # y_test_labels = y_test\n",
    "\n",
    "    # Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "    (x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "    (y_train, y_valid) = y_train[5000:], np.array(y_train[:5000]).squeeze()\n",
    "\n",
    "    # Reshape input data from (28, 28) to (28, 28, 1)\n",
    "    w, h = 28, 28\n",
    "    x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8d7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "## Look at softmax output matrices for all sets of images ##\n",
    "############################################################\n",
    "\n",
    "# define constants and params\n",
    "MAX_ITER = 25\n",
    "labels = [\"0\",  # index 0\n",
    "              \"1\",  # index 1\n",
    "              \"2\",  # index 2 \n",
    "              \"3\",  # index 3 \n",
    "              \"4\",  # index 4\n",
    "              \"5\",  # index 5\n",
    "              \"6\",  # index 6 \n",
    "              \"7\",  # index 7 \n",
    "              \"8\",  # index 8 \n",
    "              \"9\"]  # index 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67907487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10, 25)\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "## Look at softmax output matrices for random images ##\n",
    "#######################################################\n",
    "# Number of learning iterations\n",
    "MAX_ITER = 25\n",
    "save_path = \"/scratch/gpfs/eysu/mock_supervised_weights/\"\n",
    "\n",
    "y_hat_train_arr = np.zeros([y_train.shape[0], len(labels), MAX_ITER])\n",
    "for i in range(MAX_ITER):\n",
    "    if i == 0:\n",
    "        y_hat_train_name = 'y_hat_train_seed'\n",
    "       \n",
    "    else:\n",
    "        y_hat_train_name = 'y_hat_train_' + 'iter' + str(i)\n",
    "        \n",
    "    # Load test set softmax outputs \n",
    "    yhtr = np.load(save_path + y_hat_train_name + '.npy')\n",
    "\n",
    "    # The first time through, use binary weight vectors to save seed array\n",
    "    # Recall that these initial labels were randomized and do not correlate to \n",
    "    # the image's given class in the dataset\n",
    "    \n",
    "    if i == 0:\n",
    "        true_class_tr = np.nonzero(yhtr)[1]   \n",
    "    y_hat_train_arr[:, :, i] = yhtr\n",
    "\n",
    "print(y_hat_train_arr.shape)\n",
    "# (55000, 10, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5fda4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 4 ... 6 6 3]\n"
     ]
    }
   ],
   "source": [
    "print(true_class_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53301bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n",
      "[[0.09852035 0.10864645 0.10129254 ... 0.10201482 0.09894045 0.09865519]\n",
      " [0.09852035 0.10864645 0.10129254 ... 0.10201482 0.09894045 0.09865519]\n",
      " [0.09852035 0.10864645 0.10129254 ... 0.10201482 0.09894045 0.09865519]\n",
      " ...\n",
      " [0.09852035 0.10864645 0.10129254 ... 0.10201482 0.09894045 0.09865519]\n",
      " [0.09852035 0.10864645 0.10129254 ... 0.10201482 0.09894045 0.09865519]\n",
      " [0.09852035 0.10864645 0.10129254 ... 0.10201482 0.09894045 0.09865519]]\n",
      "[0.09852035 0.10864645 0.10129254 0.10108736 0.09855531 0.09285692\n",
      " 0.0994307  0.10201482 0.09894045 0.09865519]\n"
     ]
    }
   ],
   "source": [
    "final_pred = y_hat_train_arr[:, :, 24]\n",
    "print(final_pred.shape)\n",
    "print(final_pred)\n",
    "print(final_pred[0])\n",
    "\n",
    "# ALL OUTPUTS THE SAME. NO INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2cf7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "0.11234545454545454\n",
      "2:\n",
      "0.11232727272727273\n",
      "3:\n",
      "0.11556363636363637\n",
      "4:\n",
      "0.11234545454545454\n",
      "5:\n",
      "0.11270909090909091\n",
      "6:\n",
      "0.11245454545454546\n",
      "7:\n",
      "0.11252727272727273\n",
      "8:\n",
      "0.11234545454545454\n",
      "9:\n",
      "0.11230909090909091\n",
      "10:\n",
      "0.11238181818181818\n",
      "0.11273090909090908\n"
     ]
    }
   ],
   "source": [
    "# For CASE 2: \n",
    "avg_sim = 0\n",
    "for END_IDX in range(1, 11):\n",
    "    print(str(END_IDX) + \":\")\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = loadData()\n",
    "    # create empty array to store softmax outputs\n",
    "    y_hat_train_arr = np.zeros([y_train.shape[0], 10, MAX_ITER])\n",
    "\n",
    "    for case in [\"LR_adjusted/\"]:\n",
    "        save_path = \"/scratch/gpfs/eysu/low_shot_weights/\" + str(END_IDX) + \"/\" + case\n",
    "\n",
    "        edit_name = False\n",
    "        if case == \"LR_adjusted/\":\n",
    "            edit_name = True\n",
    "\n",
    "        # store the softmax vector from every iteration of training into y_hat_train_arr\n",
    "        for i in range(MAX_ITER):\n",
    "            if i == 0:\n",
    "                if edit_name: y_hat_train_name = 'LR_adjustedy_hat_train_seed'\n",
    "                else: y_hat_train_name = 'y_hat_train_seed'\n",
    "\n",
    "            else:\n",
    "                if edit_name: y_hat_train_name = 'LR_adjustedy_hat_train_' + 'iter' + str(i)\n",
    "                else: y_hat_train_name = 'y_hat_train_' + 'iter' + str(i)\n",
    "\n",
    "            # Load test set softmax outputs \n",
    "            yhtr = np.load(save_path + y_hat_train_name + '.npy')\n",
    "\n",
    "            if i == 0:\n",
    "                true_class_tr = np.nonzero(yhtr)[1]   \n",
    "            y_hat_train_arr[:, :, i] = yhtr\n",
    "            \n",
    "            final_max_predictions = np.argmax(y_hat_train_arr[:,:, 1], axis=1)\n",
    "            \n",
    "    # final max predictions still only class 1\n",
    "#     print(final_max_predictions.shape)\n",
    "#     print(true_class_tr.shape)\n",
    "    \n",
    "    frac_correct = np.count_nonzero(np.where(final_max_predictions - true_class_tr == 0))/55000\n",
    "    \n",
    "    print(frac_correct)\n",
    "    \n",
    "#     cos_sim = np.dot(true_class_tr, final_max_predictions)/(np.linalg.norm(true_class_tr)*np.linalg.norm(final_max_predictions))\n",
    "    \n",
    "    avg_sim += frac_correct\n",
    "#     print(cos_sim)\n",
    "    final_pred = y_hat_train_arr[:, :, 24]\n",
    "\n",
    "avg_sim = avg_sim/10\n",
    "print(avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2225472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "0.18725454545454545\n",
      "2:\n",
      "0.30185454545454543\n",
      "3:\n",
      "0.4073818181818182\n",
      "4:\n",
      "0.5077818181818182\n",
      "5:\n",
      "0.5991818181818181\n",
      "6:\n",
      "0.6921818181818182\n",
      "7:\n",
      "0.7899272727272727\n",
      "8:\n",
      "0.8936363636363637\n",
      "9:\n",
      "0.9904363636363637\n",
      "10:\n",
      "0.995890909090909\n",
      "0.6365527272727273\n"
     ]
    }
   ],
   "source": [
    "# For CASE 3: \n",
    "avg_sim = 0\n",
    "for END_IDX in range(1, 11):\n",
    "    print(str(END_IDX) + \":\")\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = loadData()\n",
    "    # create empty array to store softmax outputs\n",
    "    y_hat_train_arr = np.zeros([y_train.shape[0], 10, MAX_ITER])\n",
    "\n",
    "    for case in [\"shuffle_some/\"]:\n",
    "        save_path = \"/scratch/gpfs/eysu/low_shot_weights/\" + str(END_IDX) + \"/\" + case\n",
    "\n",
    "        edit_name = False\n",
    "        if case == \"LR_adjusted/\":\n",
    "            edit_name = True\n",
    "\n",
    "        # store the softmax vector from every iteration of training into y_hat_train_arr\n",
    "        for i in range(MAX_ITER):\n",
    "            if i == 0:\n",
    "                if edit_name: y_hat_train_name = 'LR_adjustedy_hat_train_seed'\n",
    "                else: y_hat_train_name = 'y_hat_train_seed'\n",
    "\n",
    "            else:\n",
    "                if edit_name: y_hat_train_name = 'LR_adjustedy_hat_train_' + 'iter' + str(i)\n",
    "                else: y_hat_train_name = 'y_hat_train_' + 'iter' + str(i)\n",
    "\n",
    "            # Load test set softmax outputs \n",
    "            yhtr = np.load(save_path + y_hat_train_name + '.npy')\n",
    "\n",
    "            if i == 0:\n",
    "                true_class_tr = np.nonzero(yhtr)[1]   \n",
    "            y_hat_train_arr[:, :, i] = yhtr\n",
    "            \n",
    "            final_max_predictions = np.argmax(y_hat_train_arr[:,:, 14], axis=1)\n",
    "            \n",
    "    # final max predictions still only class 1\n",
    "#     print(final_max_predictions.shape)\n",
    "#     print(true_class_tr.shape)\n",
    "    \n",
    "    frac_correct = np.count_nonzero(np.where(final_max_predictions - true_class_tr == 0))/55000\n",
    "    \n",
    "    print(frac_correct)\n",
    "    \n",
    "#     cos_sim = np.dot(true_class_tr, final_max_predictions)/(np.linalg.norm(true_class_tr)*np.linalg.norm(final_max_predictions))\n",
    "    \n",
    "    avg_sim += frac_correct\n",
    "#     print(cos_sim)\n",
    "    final_pred = y_hat_train_arr[:, :, 24]\n",
    "#     print(final_pred[0])\n",
    "\n",
    "avg_sim = avg_sim/10\n",
    "print(avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "077abfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "0.9169818181818182\n",
      "2:\n",
      "0.9598545454545454\n",
      "3:\n",
      "0.9675818181818182\n",
      "4:\n",
      "0.9721818181818181\n",
      "5:\n",
      "0.9730363636363636\n",
      "6:\n",
      "0.9794545454545455\n",
      "7:\n",
      "0.9802909090909091\n",
      "8:\n",
      "0.9858363636363636\n",
      "9:\n",
      "0.9906\n",
      "10:\n",
      "0.9959090909090909\n",
      "0.9721727272727273\n"
     ]
    }
   ],
   "source": [
    "# For CASE 4: \n",
    "avg_sim = 0\n",
    "for END_IDX in range(1, 11):\n",
    "    print(str(END_IDX) + \":\")\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = loadData()\n",
    "    # create empty array to store softmax outputs\n",
    "    y_hat_train_arr = np.zeros([y_train.shape[0], 10, MAX_ITER])\n",
    "\n",
    "    for case in [\"shuffle_none/\"]:\n",
    "        save_path = \"/scratch/gpfs/eysu/low_shot_weights/\" + str(END_IDX) + \"/\" + case\n",
    "\n",
    "        edit_name = False\n",
    "        if case == \"LR_adjusted/\":\n",
    "            edit_name = True\n",
    "\n",
    "        # store the softmax vector from every iteration of training into y_hat_train_arr\n",
    "        for i in range(MAX_ITER):\n",
    "            if i == 0:\n",
    "                if edit_name: y_hat_train_name = 'LR_adjustedy_hat_train_seed'\n",
    "                else: y_hat_train_name = 'y_hat_train_seed'\n",
    "\n",
    "            else:\n",
    "                if edit_name: y_hat_train_name = 'LR_adjustedy_hat_train_' + 'iter' + str(i)\n",
    "                else: y_hat_train_name = 'y_hat_train_' + 'iter' + str(i)\n",
    "\n",
    "            # Load test set softmax outputs \n",
    "            yhtr = np.load(save_path + y_hat_train_name + '.npy')\n",
    "\n",
    "            if i == 0:\n",
    "                true_class_tr = np.nonzero(yhtr)[1]   \n",
    "            y_hat_train_arr[:, :, i] = yhtr\n",
    "            \n",
    "            final_max_predictions = np.argmax(y_hat_train_arr[:,:, 14], axis=1)\n",
    "            \n",
    "    # final max predictions still only class 1\n",
    "#     print(final_max_predictions.shape)\n",
    "#     print(true_class_tr.shape)\n",
    "    \n",
    "    frac_correct = np.count_nonzero(np.where(final_max_predictions - true_class_tr == 0))/55000\n",
    "    \n",
    "    print(frac_correct)\n",
    "    \n",
    "#     cos_sim = np.dot(true_class_tr, final_max_predictions)/(np.linalg.norm(true_class_tr)*np.linalg.norm(final_max_predictions))\n",
    "    \n",
    "    avg_sim += frac_correct\n",
    "#     print(cos_sim)\n",
    "    final_pred = y_hat_train_arr[:, :, 24]\n",
    "#     print(final_pred[0])\n",
    "\n",
    "avg_sim = avg_sim/10\n",
    "print(avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d9335af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000,)\n",
      "(55000,)\n",
      "0.9799272727272728\n"
     ]
    }
   ],
   "source": [
    "# What about for unitialized model? \n",
    "\n",
    "MAX_ITER = 25\n",
    "save_path = \"/scratch/gpfs/eysu/mock_supervised_weights/\"\n",
    "    \n",
    "true_class_tr = np.load(\"/scratch/gpfs/eysu/Serial-Reproductions-CNN-Research/weights_concise/weights_digits_1_trunc/y_hat_train_seed_DigitMNIST_TRAINED_.npy\")\n",
    "true_class_tr = np.nonzero(true_class_tr)[1]\n",
    "final_pred = np.load(\"/scratch/gpfs/eysu/Serial-Reproductions-CNN-Research/weights_concise/weights_digits_1_trunc/y_hat_train_iter24_DigitMNIST_TRAINED_.npy\")\n",
    "\n",
    "\n",
    "final_max_predictions = np.argmax(final_pred, axis=1)\n",
    "\n",
    "# final max predictions still only class 1\n",
    "print(final_max_predictions.shape)\n",
    "print(true_class_tr.shape)\n",
    "\n",
    "frac_correct = np.count_nonzero(np.where(final_max_predictions - true_class_tr == 0))/55000\n",
    "\n",
    "print(frac_correct)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4baeed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
