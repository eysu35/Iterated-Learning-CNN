{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2047e4ac",
   "metadata": {},
   "source": [
    "# Copy of KNN_Confusions.ipynb \n",
    "Except this copy now pulls the activations from the last layer latent space of the model after 1 iteration of training rather than 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Libraries ##\n",
    "###############\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d48350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in mnist digit data\n",
    "all_data = np.load(\"/scratch/gpfs/eysu/src_data/mnist.npz\")\n",
    "print(all_data.files)\n",
    "x_test = all_data['x_test']\n",
    "x_train = all_data['x_train']\n",
    "y_train = all_data['y_train']\n",
    "y_test = all_data['y_test']\n",
    "\n",
    "# Split data and reset dimensions\n",
    "labels = [\"0\",  # index 0\n",
    "          \"1\",  # index 1\n",
    "          \"2\",  # index 2 \n",
    "          \"3\",  # index 3 \n",
    "          \"4\",  # index 4\n",
    "          \"5\",  # index 5\n",
    "          \"6\",  # index 6 \n",
    "          \"7\",  # index 7 \n",
    "          \"8\",  # index 8 \n",
    "          \"9\"]  # index 9\n",
    "\n",
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# save train labels\n",
    "y_train_labels = y_train\n",
    "y_test_labels = y_test\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# Validation set\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa329f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Recreate model from final iterations of SR ##\n",
    "################################################\n",
    "\n",
    "# specify path of model to load in\n",
    "# NOW USING ITER1 MODEL\n",
    "model_weights = 'Serial-Reproductions-CNN-Research/weights_concise/weights_digits_1_trunc/model.weights.best.iter1.hdf5'\n",
    "\n",
    "# load model\n",
    "model = load_model(model_weights)\n",
    "\n",
    "# examine model\n",
    "model.summary()\n",
    "model.get_weights()\n",
    "model.optimizer\n",
    "\n",
    "layer_output = model.layers[-2].output\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_output)\n",
    "\n",
    "# Run image through model and get activations\n",
    "activations = activation_model.predict(x_train) # should be 2 numpy arrays of dimension N images x 256D\n",
    "\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3112398",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Find Nearest Neighbors ##\n",
    "############################\n",
    "\n",
    "NUM_IMAGES = x_train.shape[0]\n",
    "NUM_NEIGHBORS = 25\n",
    "\n",
    "# create arrays to store results\n",
    "nearest_neighbors_in_class = np.zeros([NUM_IMAGES, NUM_NEIGHBORS])\n",
    "nearest_neighbors_in_class_norms = np.zeros([NUM_IMAGES, NUM_NEIGHBORS])\n",
    "nearest_neighbors_other_class = np.zeros([NUM_IMAGES, NUM_NEIGHBORS])\n",
    "nearest_neighbors_other_class_norms = np.zeros([NUM_IMAGES, NUM_NEIGHBORS])\n",
    "\n",
    "\n",
    "for image_idx in range(NUM_IMAGES):\n",
    "    # determine image class and divide indices by in/out of class\n",
    "    image_class = y_train[image_idx]\n",
    "    same_class_idxs = np.array(np.where(y_train == image_class)).squeeze()\n",
    "    other_class_idxs = np.array(np.where(y_train != image_class)).squeeze()\n",
    "\n",
    "    # find norm of differences between original image and every other image\n",
    "    diffs = activations - activations[image_idx]\n",
    "    norms = np.linalg.norm(diffs, axis=1)\n",
    "\n",
    "    # get nearest neighbors in and out of class\n",
    "    min_in_class_idxs = np.argpartition(norms[same_class_idxs], range(25))\n",
    "    min_other_class_idxs = np.argpartition(norms[other_class_idxs], range(25))\n",
    "    \n",
    "    # this is a bit confusing but since np.argpartition returns the indices of the min\n",
    "    # values in the subarray that we pass it, we need to use the in_class_idxs and other_class_idxs\n",
    "    # arrays to convert these indices back to the main array indices\n",
    "    min_in_class_idxs = same_class_idxs[min_in_class_idxs]\n",
    "    min_other_class_idxs = other_class_idxs[min_other_class_idxs]\n",
    "    \n",
    "    # update all results arrays\n",
    "    # start with the 2nd index since the nearest neighbor is always itself\n",
    "    nearest_neighbors_in_class[image_idx, :] = min_in_class_idxs[1:26]\n",
    "    nearest_neighbors_in_class_norms[image_idx, :] = norms[min_in_class_idxs[1:26]]\n",
    "    \n",
    "    nearest_neighbors_other_class[image_idx, :] = min_other_class_idxs[1:26]\n",
    "    nearest_neighbors_other_class_norms[image_idx, :] = norms[min_other_class_idxs[1:26]]\n",
    "    \n",
    "    # rudimentary method of tracking progress\n",
    "    if image_idx % 100 == 0:\n",
    "        print(image_idx / NUM_IMAGES)\n",
    "        \n",
    "nearest_neighbors_in_class = nearest_neighbors_in_class.astype(int)\n",
    "nearest_neighbors_other_class = nearest_neighbors_other_class.astype(int)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export nearest neighbors of all images\n",
    "import pandas as pd\n",
    "pd.DataFrame(nearest_neighbors_in_class).to_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_iter1.csv\", sep = ',', header=None, index=None)\n",
    "pd.DataFrame(nearest_neighbors_in_class_norms).to_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_norms_iter1.csv\", sep = ',', header=None, index=None)\n",
    "\n",
    "pd.DataFrame(nearest_neighbors_other_class).to_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_iter1.csv\", sep = ',', header=None, index=None)\n",
    "pd.DataFrame(nearest_neighbors_other_class_norms).to_csv(\"Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_norms_iter1.csv\", sep = ',', header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed234fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename iter 1 model matrices and load in iter 24 model matrices\n",
    "import pandas as pd\n",
    "\n",
    "# iter 1 matrices\n",
    "nearest_neighbors_in_class_iter1 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_in_class_norms_iter1 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_norms_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class_iter1 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class_norms_iter1 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_norms_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "\n",
    "# iter 24 matrices\n",
    "nearest_neighbors_in_class_iter24 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_in_class.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_in_class_norms_iter24 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_norms.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class_iter24 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_other_class.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class_norms_iter24 = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_norms.csv\", sep = ',', header=None).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "from scipy.stats import kendalltau\n",
    "NUM_IMAGES = x_train.shape[0]\n",
    "\n",
    "in_class_corr = np.zeros(NUM_IMAGES)\n",
    "other_class_corr = np.zeros(NUM_IMAGES)\n",
    "\n",
    "for image_idx in range(NUM_IMAGES):\n",
    "    in_class_corr[image_idx] = kendalltau(nearest_neighbors_in_class_iter1[image_idx, :], nearest_neighbors_in_class_iter24[image_idx, :])[0]\n",
    "    other_class_corr[image_idx] = kendalltau(nearest_neighbors_other_class_iter1[image_idx, :], nearest_neighbors_other_class_iter24[image_idx, :])[0]\n",
    "    \n",
    "print(\"Average in class correlation: \", np.mean(np.absolute(in_class_corr)))\n",
    "print(\"Average out of class correlation: \", np.mean(np.absolute(other_class_corr)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b71ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nearest_neighbors_other_class_iter1[0])\n",
    "print(nearest_neighbors_other_class_iter24[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "print(kendalltau(nearest_neighbors_other_class_iter1[0], nearest_neighbors_other_class_iter24[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf711b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(nearest_neighbors_other_class_iter1[0], nearest_neighbors_other_class_iter24[0])[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0ad03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
