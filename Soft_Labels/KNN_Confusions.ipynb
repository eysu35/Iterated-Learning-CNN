{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2047e4ac",
   "metadata": {},
   "source": [
    "# KNN_Confusions.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Libraries ##\n",
    "###############\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in mnist digit data\n",
    "all_data = np.load(\"/scratch/gpfs/eysu/src_data/mnist.npz\")\n",
    "print(all_data.files)\n",
    "x_test = all_data['x_test']\n",
    "x_train = all_data['x_train']\n",
    "y_train = all_data['y_train']\n",
    "y_test = all_data['y_test']\n",
    "\n",
    "# Split data and reset dimensions\n",
    "labels = [\"0\",  # index 0\n",
    "          \"1\",  # index 1\n",
    "          \"2\",  # index 2 \n",
    "          \"3\",  # index 3 \n",
    "          \"4\",  # index 4\n",
    "          \"5\",  # index 5\n",
    "          \"6\",  # index 6 \n",
    "          \"7\",  # index 7 \n",
    "          \"8\",  # index 8 \n",
    "          \"9\"]  # index 9\n",
    "\n",
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# save train labels\n",
    "y_train_labels = y_train\n",
    "y_test_labels = y_test\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# Validation set\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d958ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Recreate model from final iterations of SR ##\n",
    "################################################\n",
    "\n",
    "# specify path of model to load in\n",
    "model_weights = 'Serial-Reproductions-CNN-Research/weights_concise/weights_digits_1_trunc/model.weights.best.iter24.hdf5'\n",
    "\n",
    "# load model\n",
    "model = load_model(model_weights)\n",
    "\n",
    "# examine model\n",
    "model.summary()\n",
    "model.get_weights()\n",
    "model.optimizer\n",
    "\n",
    "layer_output = model.layers[-2].output\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_output)\n",
    "\n",
    "# Run image through model and get activations\n",
    "activations = activation_model.predict(x_train) # should be 2 numpy arrays of dimension N images x 256D\n",
    "\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b186f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "## Read prediction softmax layer activations for all test set images, and all iterations ##\n",
    "###########################################################################################\n",
    "DATASET = '_DigitMNIST' \n",
    "REGIME = '_TRAINED_'\n",
    "\n",
    "MAX_ITER = 25\n",
    "\n",
    "# Build arrays of dimensions: N training images X L labels X P iterations\n",
    "y_hat_train_arr = np.zeros([y_train.shape[0], len(labels), MAX_ITER])\n",
    "y_hat_test_arr = np.zeros([y_test.shape[0], len(labels), MAX_ITER])\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    if i == 0:\n",
    "        y_hat_train_name = 'y_hat_train_seed'\n",
    "        y_hat_test_name = 'y_hat_test_seed'\n",
    "    \n",
    "    else:\n",
    "        y_hat_train_name = 'y_hat_train_' + 'iter' + str(i)\n",
    "        y_hat_test_name = 'y_hat_test_' + 'iter' + str(i)\n",
    "        \n",
    "    # Load test set softmax outputs \n",
    "    yhtr = np.load('/scratch/gpfs/eysu/mock_supervised_weights/' + y_hat_train_name + '.npy')\n",
    "    yhte = np.load('/scratch/gpfs/eysu/mock_supervised_weights/' + y_hat_test_name + '.npy')  \n",
    "\n",
    "    # The first time through, use binary weight vectors to save correct class array\n",
    "    if i == 0:\n",
    "        true_class_tr = np.nonzero(yhtr)[1]\n",
    "        true_class_te = np.nonzero(yhte)[1]\n",
    "        \n",
    "    y_hat_train_arr[:, :, i] = yhtr\n",
    "    y_hat_test_arr[:, :, i] = yhte\n",
    "    \n",
    "    final_predictions = np.argmax(y_hat_train_arr[:,:, 24], axis=1)\n",
    "\n",
    "\n",
    "print(y_hat_train_arr.shape)\n",
    "# (55000, 50, 10)\n",
    "print(y_hat_test_arr.shape)\n",
    "# (10000, 50, 10)\n",
    "print(final_predictions.shape)\n",
    "# (55000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e763cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Load Nearest Neighbors ##\n",
    "############################\n",
    "\n",
    "# code to import nearest neighbors matrices\n",
    "import pandas as pd\n",
    "# read in 55000 x 25 matrices of 25 nearest in class neighbors and their norms\n",
    "\n",
    "# digits\n",
    "nearest_neighbors_in_class = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_in_class_norms = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_in_class_norms_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "\n",
    "nearest_neighbors_other_class = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "nearest_neighbors_other_class_norms = pd.read_csv(\"Serial-Reproductions-CNN-Research/Outputs/NearestNeighbors/digits/nearest_neighbors_other_class_norms_iter1.csv\", sep = ',', header=None).to_numpy()\n",
    "\n",
    "# fashion\n",
    "# nearest_neighbors_in_class = pd.read_csv(\"Outputs/NearestNeighbors/fashion/nearest_neighbors_in_class.csv\", sep = ',', header=None).to_numpy()\n",
    "# nearest_neighbors_in_class_norms = pd.read_csv(\"Outputs/NearestNeighbors/fashion/nearest_neighbors_in_class_norms.csv\", sep = ',', header=None).to_numpy()\n",
    "\n",
    "# nearest_neighbors_other_class = pd.read_csv(\"Outputs/NearestNeighbors/fashion/nearest_neighbors_other_class.csv\", sep = ',', header=None).to_numpy()\n",
    "# nearest_neighbors_other_class_norms = pd.read_csv(\"Outputs/NearestNeighbors/fashion/nearest_neighbors_other_class_norms.csv\", sep = ',', header=None).to_numpy()\n",
    "\n",
    "print(nearest_neighbors_in_class.shape)\n",
    "print(nearest_neighbors_in_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Helper Function Make 9XN plots of 4 nearest in ##\n",
    "## and out of class neighbors for given image     ##\n",
    "####################################################\n",
    "\n",
    "\n",
    "def helper_plot_4NN(image_idx):\n",
    "    # plot image in center with 4 least confusing in and out of class image alongside\n",
    "    figure = plt.figure(figsize=(20, 8), constrained_layout=True)\n",
    "    spec = figure.add_gridspec(ncols=9, nrows=1)\n",
    "\n",
    "    ax1 = figure.add_subplot(spec[0,0], xticks=[], yticks=[])\n",
    "    im1 = ax1.imshow(x_train[nearest_neighbors_in_class[image_idx, 3]], cmap='gray')\n",
    "    ax1.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_in_class[image_idx, 3]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_in_class_norms[image_idx, 3], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_in_class[image_idx, 3]]]), color = 'green')\n",
    "\n",
    "    ax2 = figure.add_subplot(spec[0,1], xticks=[], yticks=[])\n",
    "    im2 = ax2.imshow(x_train[nearest_neighbors_in_class[image_idx, 2]], cmap='gray')\n",
    "    ax2.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_in_class[image_idx, 2]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_in_class_norms[image_idx, 2], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_in_class[image_idx, 2]]]), color = 'green')\n",
    "    \n",
    "    ax3 = figure.add_subplot(spec[0,2], xticks=[], yticks=[])\n",
    "    im3 = ax3.imshow(x_train[nearest_neighbors_in_class[image_idx, 1]], cmap='gray')\n",
    "    ax3.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_in_class[image_idx, 1]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_in_class_norms[image_idx, 1], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_in_class[image_idx, 1]]]), color = 'green')\n",
    "\n",
    "    ax4 = figure.add_subplot(spec[0,3], xticks=[], yticks=[])\n",
    "    im4 = ax4.imshow(x_train[nearest_neighbors_in_class[image_idx, 0]], cmap='gray')\n",
    "    ax4.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_in_class[image_idx, 0]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_in_class_norms[image_idx, 0], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_in_class[image_idx, 0]]]), color = 'green')\n",
    "\n",
    "    ax5 = figure.add_subplot(spec[0,4], xticks=[], yticks=[])\n",
    "    im5 = ax5.imshow(x_train[image_idx], cmap='gray')\n",
    "    ax5.set_title(\"Class: \" + str(labels[y_train[image_idx]]) + \"\\nImage\" + \n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[image_idx]]), color = 'green')\n",
    "\n",
    "\n",
    "    ax6 = figure.add_subplot(spec[0,5], xticks=[], yticks=[])\n",
    "    im6 = ax6.imshow(x_train[nearest_neighbors_other_class[image_idx, 0]], cmap='gray')\n",
    "    ax6.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_other_class[image_idx, 0]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_other_class_norms[image_idx, 0], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_other_class[image_idx, 0]]]), color = 'red')\n",
    "    \n",
    "    ax7 = figure.add_subplot(spec[0,6], xticks=[], yticks=[])\n",
    "    im7 = ax7.imshow(x_train[nearest_neighbors_other_class[image_idx, 1]], cmap='gray')\n",
    "    ax7.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_other_class[image_idx, 1]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_other_class_norms[image_idx, 1], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_other_class[image_idx, 1]]]), color = 'red')\n",
    "  \n",
    "                  \n",
    "    ax8 = figure.add_subplot(spec[0,7], xticks=[], yticks=[])\n",
    "    im8 = ax8.imshow(x_train[nearest_neighbors_other_class[image_idx, 2]], cmap='gray')\n",
    "    ax8.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_other_class[image_idx, 2]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_other_class_norms[image_idx, 2], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_other_class[image_idx, 2]]]), color = 'red')\n",
    "   \n",
    "\n",
    "    ax9 = figure.add_subplot(spec[0,8], xticks=[], yticks=[])\n",
    "    im9 = ax9.imshow(x_train[nearest_neighbors_other_class[image_idx, 3]], cmap='gray')\n",
    "    ax9.set_title(\"Class: \" + str(labels[y_train[nearest_neighbors_other_class[image_idx, 3]]]) + \n",
    "                  \"\\nNorm diff: \" + str(np.around(nearest_neighbors_other_class_norms[image_idx, 3], 3)) +\n",
    "                  \"\\nFinal predicted class: \" + str(labels[final_predictions[nearest_neighbors_other_class[image_idx, 3]]]), color = 'red')\n",
    "\n",
    "    plt.show()\n",
    "    return figure\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "## Helper Function for 4xN plots ##\n",
    "###################################\n",
    "\n",
    "def print_images_helper(index, softmax, image, title):\n",
    "    figure = plt.figure(figsize=(40, 40))\n",
    "    # plot image\n",
    "    ax1 = figure.add_subplot(8, 8, 1, xticks=[], yticks=[])\n",
    "    im1 = ax1.imshow(image, cmap='gray')\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    # plot weights graph\n",
    "    if (softmax[:, 0].all() == softmax[:, 1].all()):\n",
    "        title_str = \"Softmax Outputs (iter 1 same)\"\n",
    "        \n",
    "    else: title_str = \"Softmax Outputs\"\n",
    "        \n",
    "    ax2 = figure.add_subplot(8, 8, 2)\n",
    "    im2 = ax2.imshow(softmax.T, cmap='Wistia')\n",
    "    \n",
    "    divider = make_axes_locatable(ax2)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    cbar = figure.colorbar(im2, cax=cax, ticks=[0, 1])\n",
    "    cbar.ax.set_yticklabels(['0', '1'])\n",
    "\n",
    "    ax2.set(xlabel='Classes', ylabel='Iterations', title=title_str)\n",
    "    ax2.set_xticks(ticks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax2.set_xticklabels(labels, rotation = 'vertical')\n",
    "\n",
    "    # plot correlation graph\n",
    "    corr_arr = np.corrcoef(softmax.T)\n",
    "\n",
    "    ax3 = figure.add_subplot(8, 8, 3)\n",
    "    im3 = ax3.imshow(corr_arr, cmap='Wistia')\n",
    "    divider = make_axes_locatable(ax3)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    cbar = figure.colorbar(im2, cax=cax, orientation='vertical', ticks=[0, 1])\n",
    "    cbar.ax.set_yticklabels(['0', '1'])\n",
    "    ax3.set_title(\"Correlation Matrix\")\n",
    "\n",
    "    # plot eigenvalues graph\n",
    "    eigs, _ = np.linalg.eig(corr_arr)\n",
    "    num_nonzero = np.count_nonzero(np.around(eigs, 2))\n",
    "\n",
    "    if (num_nonzero == 1):\n",
    "        title_str = \"Sorted Eigenvalues (\" + str(num_nonzero) + \" nonzero)\"\n",
    "    else:\n",
    "        title_str = \"Sorted Eigenvalues (\" + str(num_nonzero) + \" nonzeros)\"\n",
    "\n",
    "    ax4 = figure.add_subplot(8, 8, 4)\n",
    "    im4 = ax4.plot(eigs, marker='o')\n",
    "    ax4.set(xlabel=\"PC Number\", xlim=[0,len(eigs)], ylim=[0,MAX_ITER], title=title_str)\n",
    "\n",
    "    plt.show()\n",
    "    return figure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e07d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## Visualize N images ##\n",
    "########################\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "def visualize_N_images(CLASS, NUM_IMAGES, rank):\n",
    "    print(\"Class: \", CLASS)\n",
    "    # least confusing\n",
    "    \n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"Serial-Reproductions-CNN-Research/NearestNeighborsUpdate/Iter1/least_confusing_\" + str(labels[CLASS]) + \"s.pdf\")\n",
    "    print(str(NUM_IMAGES) + \" least confusing \" + str(labels[CLASS]) + \"s\")\n",
    "    for i in range(NUM_IMAGES):\n",
    "        # get index of image\n",
    "        image_idx = rank[i]\n",
    "        \n",
    "        # print image itself\n",
    "        figure = print_images_helper(image_idx, y_hat_train_arr[image_idx], x_train[image_idx], \"Original Image\")\n",
    "        pdf.savefig(figure, bbox_inches='tight')\n",
    "\n",
    "        figure2 = helper_plot_4NN(image_idx)\n",
    "        pdf.savefig(figure2, bbox_inches='tight')\n",
    "        \n",
    "    pdf.close()\n",
    "\n",
    "    # most confusing\n",
    "    \n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"Serial-Reproductions-CNN-Research/NearestNeighborsUpdate/Iter1/most_confusing_\" + str(labels[CLASS]) + \"s.pdf\")\n",
    "    print(str(NUM_IMAGES) + \" most confusing \" + str(labels[CLASS]) + \"s\")\n",
    "    for i in range(NUM_IMAGES):\n",
    "        # get index of image\n",
    "        image_idx = rank[-NUM_IMAGES + i]\n",
    "        \n",
    "        # print image itself\n",
    "        figure = print_images_helper(image_idx, y_hat_train_arr[image_idx], x_train[image_idx], \"Original Image\")\n",
    "        pdf.savefig(figure, bbox_inches='tight')\n",
    "\n",
    "        figure2 = helper_plot_4NN(image_idx)\n",
    "        pdf.savefig(figure2, bbox_inches='tight')\n",
    "        \n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Rank by difference to binary seed vector ##\n",
    "##############################################\n",
    "\n",
    "# Call visualization methods and generate PDFs from here\n",
    "\n",
    "for i in range(10):\n",
    "    # choose which class to analyze\n",
    "    CLASS = i\n",
    "    same_class_idxs = np.array(np.where(y_train == CLASS)).squeeze()\n",
    "    class_data = y_hat_train_arr[np.where(true_class_tr == CLASS), :, :].squeeze()\n",
    "    diff_arr = class_data[:, CLASS, 0] - class_data[:, CLASS, MAX_ITER - 1]\n",
    "    seed_diff_rank = np.argsort(diff_arr)\n",
    "    \n",
    "    # again, convert subarray indices back to master indices\n",
    "    seed_diff_rank = same_class_idxs[seed_diff_rank]\n",
    "    print(seed_diff_rank)\n",
    "    visualize_N_images(i, 50, seed_diff_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0893b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38caff89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
